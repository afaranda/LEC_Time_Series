setwd('/home/adam/Desktop/Sam_ICL_Figures_December_2019')
wd<-getwd()
outDir<-paste(wd,'DiffExp',sep='/')
library(edgeR)
library(dplyr)
library(ggplot2)
source('BuildDataMatrix.R')
#options(echo=T)
dl<-paste(wd,c("DNA_Link_HTSeq_Counts", "DBI_HTSeq_Counts"),sep="/")
ft<-hc_getFileTable(dirList=dl)
ft$Interval<-factor(paste0(ft$Hours_PCS, "H"), levels=c("0H","6H","24H","48H","120H"))
# Load in Count Data and Join Gene Lengths
ds<-hc_loadFiles(ft)
df<-as.data.frame(hc_buildDataFrame(ds,ft)[[2]])
gt<-read.table(
'gene_coding_lengths.txt',
header=T, quote="", sep="\t",
stringsAsFactors = F
)
row.names(gt)<-gt$gene_id
y<-DGEList(
counts = df,
genes = gt[row.names(df),],
samples = ft,
)
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval+Lab, ft)
rownames(design)<-colnames(y)
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-estimateCommonDisp(z)
z<-estimateTagwiseDisp(z)
z<-calcNormFactors(z)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmFit(z, design)
qlf<-glmLRT(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
#
#List of Genes over which to tabulate time series
# Un-comment genes that you would like to generate a table for
genes<-c(
Egr1="ENSMUSG00000038418",
#Grem1="ENSMUSG00000074934",
#Ptx3="ENSMUSG00000027832",
#Fn1="ENSMUSG00000026193",
#Actn1="ENSMUSG00000015143",
#Acta2="ENSMUSG00000035783",
#Col1a1="ENSMUSG00000001506",
#Atf3="ENSMUSG00000026628",
#Pitx3="ENSMUSG00000025229",
#Klf2="ENSMUSG00000055148",
#Emp1="ENSMUSG00000030208",
#Cxcl1="ENSMUSG00000029380",
#Cxcl2="ENSMUSG00000058427",
#Cxcl5="ENSMUSG00000029371",
#`Ppbp (Cxcl7)`="ENSMUSG00000029372",
#Cxcl9="ENSMUSG00000029417",
#Cxcr2="ENSMUSG00000026180",
#Cxcr4="ENSG00000121966",
#Runx1="ENSMUSG00000022952",
#Tnc="ENSMUSG00000028364",
Fos="ENSMUSG00000021250",
Ier2="ENSMUSG00000053560",
FosB="ENSMUSG00000003545",
Jun="ENSMUSG00000052684",
JunB="ENSMUSG00000052837"
)
# Plot RPKM for EGR1, FosB, IER2, JunB, and Fos/c-Fos
fpkm<-as.data.frame(rpkm(z, gene.length="coding_length"))
fpkm$gene_id<-row.names(fpkm)
source('~/Desktop/Sam_ICL_Figures_December_2019/CalcDiffExp.R')
plt
g
g="Jun"
plt<-inner_join(
ft,
reshape2::melt(fpkm %>% filter(gene_id == genes[g])) %>%
filter(variable != "coding_length") %>%
dplyr::select(sample=variable, FPKM=value),
by="sample"
)
plt$gene_symbol<-g
plt$ensembl_id<-genes[g]
plt
# Enter Working Directory and Load Raw Data
setwd('/home/adam/Documents/Sam_ICL_Figures_December_2019')
wd<-getwd()
outDir<-paste(wd,'DiffExp',sep='/')
library(edgeR)
library(dplyr)
library(ggplot2)
source('BuildDataMatrix.R')
dl<-paste(wd,c("DNA_Link_HTSeq_Counts", "DBI_HTSeq_Counts"),sep="/")
ft<-hc_getFileTable(dirList=dl)
ft$Interval<-factor(paste0(ft$Hours_PCS, "H"), levels=c("0H","6H","24H","48H","120H"))
# Load in Count Data and Join Gene Lengths
ds<-hc_loadFiles(ft)
df<-as.data.frame(hc_buildDataFrame(ds,ft)[[2]])
gt<-read.table(
'gene_coding_lengths.txt',
header=T, quote="", sep="\t",
stringsAsFactors = F
)
row.names(gt)<-gt$gene_id
y<-DGEList(
counts = df,
genes = gt[row.names(df),],
samples = ft,
)
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval+Lab, ft)
rownames(design)<-colnames(y)
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-estimateCommonDisp(z)
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-estimateDisp(z)
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-estimateDisp(z, design)
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmFit(z, design)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmLRT(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
head(deg)
min(deg$FDR)
max(deg$FDR)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmQLFTest(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
min(deg$FDR)
head(deg)
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval, ft)
rownames(design)<-colnames(y)
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design, robust=T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmQLFTest(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
head(deg)
# Enter Working Directory and Load Raw Data
setwd('/home/adam/Documents/Sam_ICL_Figures_December_2019')
wd<-getwd()
outDir<-paste(wd,'DiffExp',sep='/')
library(edgeR)
library(dplyr)
# Enter Working Directory and Load Raw Data
setwd('/home/adam/Documents/Sam_ICL_Figures_December_2019')
wd<-getwd()
outDir<-paste(wd,'DiffExp',sep='/')
library(edgeR)
library(dplyr)
library(ggplot2)
source('BuildDataMatrix.R')
dl<-paste(wd,c("DNA_Link_HTSeq_Counts", "DBI_HTSeq_Counts"),sep="/")
ft<-hc_getFileTable(dirList=dl)
ft$Interval<-factor(paste0(ft$Hours_PCS, "H"), levels=c("0H","6H","24H","48H","120H"))
# Load in Count Data and Join Gene Lengths
ds<-hc_loadFiles(ft)
df<-as.data.frame(hc_buildDataFrame(ds,ft)[[2]])
gt<-read.table(
'gene_coding_lengths.txt',
header=T, quote="", sep="\t",
stringsAsFactors = F
)
row.names(gt)<-gt$gene_id
y<-DGEList(
counts = df,
genes = gt[row.names(df),],
samples = ft,
)
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval+batch, ft)
rownames(design)<-colnames(y)
design
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design, robust=T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmQLFTest(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
# st
#List of Genes over which to tabulate time series
# Un-comment genes that you would like to generate a table for
genes<-c(
Egr1="ENSMUSG00000038418",
#Grem1="ENSMUSG00000074934",
#Ptx3="ENSMUSG00000027832",
#Fn1="ENSMUSG00000026193",
#Actn1="ENSMUSG00000015143",
#Acta2="ENSMUSG00000035783",
#Col1a1="ENSMUSG00000001506",
#Atf3="ENSMUSG00000026628",
#Pitx3="ENSMUSG00000025229",
#Klf2="ENSMUSG00000055148",
#Emp1="ENSMUSG00000030208",
#Cxcl1="ENSMUSG00000029380",
#Cxcl2="ENSMUSG00000058427",
#Cxcl5="ENSMUSG00000029371",
#`Ppbp (Cxcl7)`="ENSMUSG00000029372",
#Cxcl9="ENSMUSG00000029417",
#Cxcr2="ENSMUSG00000026180",
#Cxcr4="ENSG00000121966",
#Runx1="ENSMUSG00000022952",
#Tnc="ENSMUSG00000028364",
Fos="ENSMUSG00000021250",
Ier2="ENSMUSG00000053560",
FosB="ENSMUSG00000003545",
Jun="ENSMUSG00000052684",
JunB="ENSMUSG00000052837"
)
head(deg)
aveLogCPM(z)
aveLogCPM(z, design)
head(z)
aveLogCPM(z, z$samples$Interval)
?aveLogCPM
cpm(z, group=z$samples$Interval)
cpmByGroup(z, group=z$samples$Interval)
cpmByGroup(z, group=z$samples$Interval)["ENSMUSG00000038418",]
x<-cpmByGroup(z, group=z$samples$Interval)["ENSMUSG00000038418",]
x
x[2:5] /x[1]
log(x[2:5] /x[1],2)
deg["ENSMUSG00000038418",]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design, robust=T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval+batch, ft)
rownames(design)<-colnames(y)
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design, robust=T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmQLFTest(fit, coef=2:5)
degA<-as.data.frame(topTags(qlf, n=Inf))
# Setup Design Matrix for Statistical Analysis
design<-model.matrix(~Interval, ft)
rownames(design)<-colnames(y)
# Remove genes with fewer than 10 counts in 'n' samples based on design matrix
z<-y[filterByExpr(y, design=design), , keep.lib.sizes=FALSE]
# Calculate Parameter Estimates / Normalization Factors
#z<-estimateDisp(z, design=design)
z<-calcNormFactors(z)
z<-estimateDisp(z, design, robust=T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(z, design, robust=T)
qlf<-glmQLFTest(fit, coef=2:5)
degB<-as.data.frame(topTags(qlf, n=Inf))
degB['ENSMUSG00000038418',]
degA['ENSMUSG00000038418',]
?removeBatchEffect
design
?removeBatchEffect(z, design=design, batch=z$samples$batch)
removeBatchEffect(z, design=design, batch=z$samples$batch)
removeBatchEffect(cpm(z), design=design, batch=z$samples$batch)
removeBatchEffect(cpm(z, log=F), design=design, batch=z$samples$batch)
removeBatchEffect(cpm(z, log=T), design=design, batch=z$samples$batch)
x<-removeBatchEffect(cpm(z, log=T), design=design, batch=z$samples$batch)
head(x)
min(x)
2^min(x)
cpmByGroup(x, group=dge$samples$Interval)
cpmByGroup(x, group=z$samples$Interval)
cpmByGroup(2^x, group=z$samples$Interval)
a<-cpmByGroup(2^x, group=z$samples$Interval)
head(a)
a<-cpmByGroup(2^x, group=z$samples$Interval)
a
head(a)
a['ENSMUSG00000038418']
a['ENSMUSG00000038418',]
b<-a['ENSMUSG00000038418',]
b[2:5]/b[1]
log(b[2:5]/b[1],2)
# Enter Working Directory and Load Raw Data
setwd('/home/adam/Documents/Sam_ICL_Figures_December_2019')
wd<-getwd()
outDir<-paste(wd,'DiffExp',sep='/')
library(edgeR)
library(dplyr)
library(ggplot2)
source('BuildDataMatrix.R')
dl<-paste(wd,c("DNA_Link_HTSeq_Counts", "DBI_HTSeq_Counts"),sep="/")
ft<-hc_getFileTable(dirList=dl)
ft$Interval<-factor(paste0(ft$Hours_PCS, "H"), levels=c("0H","6H","24H","48H","120H"))
# Load in Count Data and Join Gene Lengths
ds<-hc_loadFiles(ft)
df<-as.data.frame(hc_buildDataFrame(ds,ft)[[2]])
gt<-read.table(
'gene_coding_lengths.txt',
header=T, quote="", sep="\t",
stringsAsFactors = F
)
source('~/Documents/Sam_ICL_Figures_December_2019/CalcDiffExp.R')
head(df)
df['ENSMUSG00000033730',]
for (g in names(genes)){
plt<-inner_join(
ft,
reshape2::melt(fpkm %>% filter(gene_id == genes[g])) %>%
filter(variable != "coding_length") %>%
dplyr::select(sample=variable, FPKM=value),
by="sample"
)
ggplot(plt, aes(x=Hours_PCS, y=FPKM, group=Interval)) + geom_point(aes(color=Lab)) + ggtitle(g)
ggsave(filename=paste(g,"_fpkm_pnt.png", sep=""), width=6, height=2)
}
for (g in names(genes)){
plt<-inner_join(
ft,
reshape2::melt(fpkm %>% filter(gene_id == genes[g])) %>%
filter(variable != "coding_length") %>%
dplyr::select(sample=variable, FPKM=value),
by="sample"
)
ggplot(plt, aes(x=Hours_PCS, y=FPKM, group=Interval)) + geom_point(aes(color=batch)) + ggtitle(g)
ggsave(filename=paste(g,"_fpkm_pnt.png", sep=""), width=6, height=2)
}
# Write Differential Expression Statistics to a file.
write.table(
deg[genes,],
file="Differential_Expression_Statistics.tsv",
quote=F, sep="\t", row.names=F
)
source('~/Documents/Melinda_LEC_TimeSeries_Targets_Set_1_April_2020/CalcDiffExp.R')
source('~/Documents/Melinda_LEC_TimeSeries_Targets_Set_1_April_2020/CalcDiffExp.R')
warnings()
source('~/Documents/Melinda_LEC_TimeSeries_Targets_Set_1_April_2020/CalcDiffExp.R')
library(edgeR)
library(WGCNA)
setwd('/home/adam/Documents/LEC_Time_Series')
min_lfc=4                                          # log fold change threshold
min_cpm=0.50                                       # Minimum overall abundance
max_cpm=20                                        # Maximum overall abundance
output_prefix="lfc4"                        # Prefix for output files
dgeFile="LTS_DGEList.Rdata"                   # Rdata file with dgelist object
## Helper Function filters a count matrix by given criteria
filterCPMmat<-function(
object = dge, samples = wt_samples, func=cpm,
lfc = 3, min_log_cpm = 0, max_log_cpm = 100, include_genes = biosig$gene_id,
lfc_columns = paste('logFC', LETTERS[1:4], sep="."), deg_table = deg
){
ecpm<-func(object, log = T)        # Generate a gene x sample log CPM matrix
# Filter differential expression table by fold change and abundance
dt<-deg_table[
apply(deg_table[,lfc_columns],
1, function(x, l=lfc) any(abs(x) > l)),
]
dt<-dt[dt$logCPM > min_log_cpm & dt$logCPM < max_log_cpm, ]
dt<-dt[dt$FDR < 0.05, ]
# If a subset of genes is provided, take the intersection
if (!is.null(include_genes)){
genes<-intersect(dt$gene_id, include_genes)
} else{
genes<-dt$gene_id
}
return(ecpm[genes, samples])
}
######################### Load and Prepare Data ##############################
load(dgeFile)
s<-master$samples[master$samples$genotype == "WT",'sample']
dge<-master[,s]
design<-model.matrix(~interval + batch, dge$samples)
colnames(design)<-gsub("interval", '', colnames(design))
keep<-filterByExpr(dge, design)
dge<-dge[keep,,keep.lib.sizes=F]
# Normalize and Estimate Dispersions
dge<-calcNormFactors(dge)
dge<-estimateDisp(dge, design, robust = T)
# Calcuate Statistical Significance (Gene DE at ANY Timepoint)
fit<-glmQLFit(dge, design)
qlf<-glmQLFTest(fit, coef=2:5)
deg<-as.data.frame(topTags(qlf, n=Inf))
# construct datExpr and datTraits using filteredGenes
datExpr<-t(
filterCPMmat(
object = dge, samples=dge$samples$sample, lfc=min_lfc,
min_log_cpm = min_cpm, max_log_cpm = max_cpm, func=cpm,
lfc_columns = paste('logFC', c('6H', '24H', '48H', '120H'), sep="."),
deg_table = deg, include_genes = NULL
)
)
# remove columns that hold information we do not need.
allTraits = dge$samples[, -c(1,2,3,5,6,8,9,10,11)];
row.names(allTraits)<-allTraits$sample
modbatch<-model.matrix(~ 0 + batch, allTraits)
modhours<-model.matrix(~ 0 + interval, allTraits)
allTraits<-merge(allTraits, modhours, by='row.names')
row.names(allTraits)<-allTraits$Row.names
allTraits<-allTraits[-1]
allTraits<-merge(allTraits, modbatch,by='row.names')
rownames(allTraits)<-allTraits$sample
allTraits<-allTraits[-1]
allTraits<-allTraits[,-c(1,2,3)]
names(allTraits)<-gsub("batch", "", names(allTraits))
names(allTraits)<-gsub("interval", "", names(allTraits))
powers = c(c(1:10), seq(from = 12, to=30, by=2))
# Call the network topology analysis function
sft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)
fn<-paste(output_prefix, "LTS_Wildtype_WGCNA_ScaleAnalysis.png", sep="_")
png(fn)
# Plot the results:
#sizeGrWindow(9, 5)
par(mfrow = c(1,2));
cex1 = 0.9;
plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
xlab="Soft Threshold (power)",ylab="Scale Free Topology Model Fit,signed R^2",type="n",
main = paste("Scale independence"));
text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
labels=powers,cex=cex1,col="red");
# this line corresponds to using an R^2 cut-off of h
abline(h=0.90,col="red")
# Mean connectivity as a function of the soft-thresholding power
plot(sft$fitIndices[,1], sft$fitIndices[,5],
xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",
main = paste("Mean connectivity"))
text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")
dev.off()
######################## Build Correlation Network ###########################
net = blockwiseModules(datExpr, power = 22,
TOMType = "unsigned", minModuleSize = 30,
reassignThreshold = 0, mergeCutHeight = 0.25,
numericLabels = TRUE, pamRespectsDendro = FALSE,
saveTOMs = TRUE,
saveTOMFileBase = "LEC_Time_Series_Wildtype",
loadTOM = F,
verbose = 3)
moduleLabels = net$colors
moduleColors = labels2colors(net$colors)
MEs = net$MEs;
geneTree = net$dendrograms[[1]]
############################### Plot Results #################################
nGenes = ncol(datExpr);
nSamples = nrow(datExpr);
# Recalculate MEs with color labels
MEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenes
MEs = orderMEs(MEs0)
moduleTraitCor = cor(MEs, allTraits, use = "p");
moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples);
textMatrix =  paste(signif(moduleTraitCor, 2), "\n(",
signif(moduleTraitPvalue, 1), ")", sep = "");
dim(textMatrix) = dim(moduleTraitCor)
fn<-paste(output_prefix, "LTS_Wildtype_WGCNA_ModuleTraitCorrelation.png" )
png(fn, width=600)
par(mar = c(6, 8.5, 3, 3));
# Display the correlation values within a heatmap plot
labeledHeatmap(Matrix = moduleTraitCor,
xLabels = names(allTraits),
yLabels = names(MEs),
ySymbols = names(MEs),
colorLabels = FALSE,
colors = blueWhiteRed(50),
textMatrix = textMatrix,
setStdMargins = FALSE,
cex.text = 1,
zlim = c(-1,1),
main = paste("Module-trait relationships"))
dev.off()
#################### Generate Line Plots For Each Module #####################
library(data.table)
library(ggplot2)
dt<-data.table(merge(datExpr, dge$samples, by='row.names'))
for(c in unique(net$colors)){
n<-labels2colors(c)
g<-names(net$colors[net$colors == c])
x<-melt(
dt[,c(g, 'interval'),with=F][,lapply(.SD, mean), by=interval],
id.vars = 'interval'
)
fn<-paste(
output_prefix,
n, "Module_Lineplot.png",
sep="_"
)
ttl<-paste(n, length(g))
ggplot(x, aes(x=interval, y=value, color=variable, group=variable)) +
geom_line() + theme(legend.position = 'none') + ggtitle(ttl)
ggsave(fn)
}
head(deg)
deg[deg$SYMBOL == 'Mrtfa',]
